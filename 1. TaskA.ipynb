{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rate My Beer Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up ChromeDriver path\n",
    "driver_path = \"/Users/ramzikattan/Downloads/chromedriver-mac-arm64/chromedriver\"\n",
    "chrome_path = \"/Applications/Google Chrome.app/Contents/MacOS/Google Chrome\"\n",
    "\n",
    "# Configure Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.binary_location = chrome_path\n",
    "\n",
    "# Set up the Chrome WebDriver service\n",
    "service = Service(driver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the webpage\n",
    "url = \"https://www.ratebeer.com/top-beers?time=all\"\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Parse the page with BeautifulSoup\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Close the browser after fetching the page\n",
    "driver.quit()\n",
    "\n",
    "# Find all <a> tags with the class containing the beer name and link\n",
    "beer_links = soup.find_all('a', class_=\"MuiTypography-root\")\n",
    "\n",
    "# Extract the name and URL for each beer\n",
    "beers = []\n",
    "for beer in beer_links:\n",
    "    name = beer.get_text(strip=True)  # Get the text (beer name)\n",
    "    link = beer['href']  # Get the URL\n",
    "    full_link = \"https://www.ratebeer.com\" + link  # Construct full URL\n",
    "    beers.append({'name': name, 'link': full_link})\n",
    "\n",
    "# Print the extracted beer names and their URLs\n",
    "#for beer in beers:\n",
    " #   print(f\"Beer: {beer['name']} - URL: {beer['link']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the matrix for only the beer links\n",
    "cleaned_beers = [beer for beer in beers[28:128] if beer['name']]  # Only keep non-empty names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beer Name</th>\n",
       "      <th>Beer Rating</th>\n",
       "      <th>Beer URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aecht Schlenkerla Rauchbier Urbock</td>\n",
       "      <td>4.0</td>\n",
       "      <td>https://www.ratebeer.com/beer/aecht-schlenkerl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Duckpond Duckpond Darkwing De Luxe</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://www.ratebeer.com/beer/duckpond-duckpon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aecht Schlenkerla Weichsel Rotbier</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://www.ratebeer.com/beer/aecht-schlenkerl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ayinger Altbairisch Dunkel</td>\n",
       "      <td>3.6</td>\n",
       "      <td>https://www.ratebeer.com/beer/ayinger-altbairi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Russian River Beatification (Batch 002+)</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://www.ratebeer.com/beer/russian-river-be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Beer Name  Beer Rating  \\\n",
       "0        Aecht Schlenkerla Rauchbier Urbock          4.0   \n",
       "1        Duckpond Duckpond Darkwing De Luxe          3.8   \n",
       "2        Aecht Schlenkerla Weichsel Rotbier          3.8   \n",
       "3                Ayinger Altbairisch Dunkel          3.6   \n",
       "4  Russian River Beatification (Batch 002+)          4.2   \n",
       "\n",
       "                                            Beer URL  \n",
       "0  https://www.ratebeer.com/beer/aecht-schlenkerl...  \n",
       "1  https://www.ratebeer.com/beer/duckpond-duckpon...  \n",
       "2  https://www.ratebeer.com/beer/aecht-schlenkerl...  \n",
       "3  https://www.ratebeer.com/beer/ayinger-altbairi...  \n",
       "4  https://www.ratebeer.com/beer/russian-river-be...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rescrape Using Nico's Links\n",
    "cleaned_beers = pd.read_csv('beer_url.csv')\n",
    "\n",
    "# Drop rows with duplicate beer names, keeping the first occurrence\n",
    "cleaned_beers = cleaned_beers.drop_duplicates(subset=['Beer Name'], keep='first')\n",
    "\n",
    "# Display the first few rows of the updated DataFrame\n",
    "cleaned_beers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Chrome options for headless mode\n",
    "chrome_options = Options()\n",
    "chrome_options.binary_location = chrome_path  # Path to your Chrome browser\n",
    "chrome_options.add_argument('--headless')  # Enable headless mode to run faster\n",
    "chrome_options.add_argument('--disable-gpu')  # Disable GPU acceleration (for better performance in headless mode)\n",
    "chrome_options.add_argument('--no-sandbox')  # Added for safe execution in certain environments\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')  # Avoid issues with shared memory\n",
    "\n",
    "# Set up the Chrome WebDriver service\n",
    "service = Service(driver_path)  # Path to your ChromeDriver\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Function to click \"Show More\" buttons on the current page\n",
    "def click_show_more_buttons():\n",
    "    # Locate all \"Show More\" buttons on the page\n",
    "    show_more_xpath = '//span[contains(@class, \"MuiButton-label\") and text()=\"Show more\"]'\n",
    "    show_more_buttons = driver.find_elements(By.XPATH, show_more_xpath)\n",
    "\n",
    "    # Click each \"Show More\" button\n",
    "    for button in show_more_buttons:\n",
    "        try:\n",
    "            if button.is_displayed():\n",
    "                driver.execute_script(\"arguments[0].click();\", button)\n",
    "                time.sleep(1)  # Wait for the content to expand\n",
    "        except:\n",
    "            pass  # Skip if there's an issue clicking the button\n",
    "\n",
    "# Function to scrape reviews on the current page\n",
    "def scrape_reviews():\n",
    "    reviews = []\n",
    "    ratings_xpath = '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"bRPQdN\", \" \" )) and contains(concat( \" \", @class, \" \" ), concat( \" \", \"MuiTypography-subtitle1\", \" \" ))]'  # Adjust this based on your page's structure for ratings\n",
    "    messages_xpath = '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"pre-wrap\", \" \" )) and contains(concat( \" \", @class, \" \" ), concat( \" \", \"MuiTypography-body1\", \" \" ))]'  # Adjust this based on your page's structure for review messages\n",
    "\n",
    "    # Find all the review ratings and messages on the current page\n",
    "    ratings = driver.find_elements(By.XPATH, ratings_xpath)\n",
    "    messages = driver.find_elements(By.XPATH, messages_xpath)\n",
    "\n",
    "    for i, message in enumerate(messages):\n",
    "        reviews.append({\n",
    "            'rating': ratings[i].text if i < len(ratings) else None,  # Handle index if ratings and messages mismatch\n",
    "            'message': message.text\n",
    "        })\n",
    "\n",
    "    return reviews\n",
    "\n",
    "# Function to scrape reviews for a single beer URL with a limit of 250 reviews\n",
    "def scrape_beer_reviews(beer_name, url, review_limit):\n",
    "    all_reviews = []\n",
    "    \n",
    "    driver.get(url)\n",
    "\n",
    "    # Handle the cookies banner by accepting it\n",
    "    try:\n",
    "        accept_cookies_id = 'onetrust-accept-btn-handler'\n",
    "        accept_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, accept_cookies_id)))\n",
    "        accept_button.click()\n",
    "    except:\n",
    "        print(\"No cookies banner found or failed to dismiss.\")\n",
    "        pass\n",
    "\n",
    "    # Loop through pages and scrape reviews until the limit is reached\n",
    "    while len(all_reviews) < review_limit:\n",
    "        # Click all \"Show More\" buttons to expand reviews\n",
    "        click_show_more_buttons()\n",
    "\n",
    "        # Scrape reviews on the current page\n",
    "        page_reviews = scrape_reviews()\n",
    "        all_reviews.extend(page_reviews)\n",
    "\n",
    "        # Check if we've hit the review limit\n",
    "        if len(all_reviews) >= review_limit:\n",
    "            all_reviews = all_reviews[:review_limit]  # Truncate to exactly the review limit\n",
    "            break\n",
    "\n",
    "        # Find the \"Next\" button and move to the next page\n",
    "        try:\n",
    "            next_button_xpath = '//button[@aria-label=\"Next page\" and contains(@class, \"MuiIconButton-root\")]'\n",
    "            next_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, next_button_xpath)))\n",
    "            next_button.click()\n",
    "\n",
    "            # Wait for the next page to load\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            # If there's no \"Next\" button, break the loop\n",
    "            print(f\"Finished scraping {beer_name}.\")\n",
    "            break\n",
    "\n",
    "    return all_reviews\n",
    "\n",
    "# Initialize an empty DataFrame to store all the reviews\n",
    "df = pd.DataFrame(columns=['Beer Name', 'URL', 'Rating', 'Review'])\n",
    "\n",
    "# Iterate through each beer in the cleaned_beers list\n",
    "for beer in cleaned_beers:\n",
    "    beer_name = beer['name']\n",
    "    beer_url = beer['link']\n",
    "\n",
    "    print(f\"Scraping reviews for {beer_name} at {beer_url}...\")\n",
    "\n",
    "    # Scrape reviews for the current beer with a limit of 250 reviews\n",
    "    reviews = scrape_beer_reviews(beer_name, beer_url, review_limit=100)\n",
    "\n",
    "    # Create a DataFrame for the reviews of the current beer\n",
    "    beer_df = pd.DataFrame(reviews)\n",
    "    beer_df['Beer Name'] = beer_name\n",
    "    beer_df['URL'] = beer_url\n",
    "\n",
    "    # Append the DataFrame for this beer to the overall DataFrame\n",
    "    df = pd.concat([df, beer_df], ignore_index=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('expanded_beer_reviews.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Close the browser after scraping all URLs\n",
    "driver.quit()\n",
    "\n",
    "print(\"Scraping completed. Data saved to 'expanded_beer_reviews.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Crowdsourced Recommender System\n",
    "\n",
    "### Group Members: Jose Currea, Jenna Ferguson, Evan Hadd, Ramzi Kattan, Hadley Krummel\n",
    "### Class Section: Afternoon 1 - 3pm\n",
    "\n",
    "It should accept user inputs in the form of desired attributes of a product and come up with 3 recommendations. \n",
    "\n",
    "**Your Python Notebook should include the following:**\n",
    "- All scripts \n",
    "- The sentiment and similarity scores for the three products you recommended in task E.\n",
    "- Your analyses for and answer to task F. Make sure you show the ratings, similarity scores and sentiments for the products you recommend in tasks E and F. Use tables whenever possible.  \n",
    "- Show the logic you are using in addition to finding the most similar product. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import Counter\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "import itertools\n",
    "from sklearn.manifold import MDS\n",
    "import statsmodels.api as sm  # For the OLS regression\n",
    "import numpy as np            # For numerical operations like log transformations\n",
    "import matplotlib.pyplot as plt  # For plotting\n",
    "from collections import Counter  # For counting word occurrences\n",
    "from scipy import stats        # For t-statistic and p-value calculations\n",
    "from sklearn import manifold\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.expand_frame_repr', False)  # Prevent wrapping to multiple lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A\n",
    "\n",
    "Extract about 5-6k reviews. However, many reviews may not have any text and will therefore be discarded. Finally you may end up with 1700-2000 reviews with text.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        messages = soup.find_all(\"div\", class_ = \"Message userContent\")\n",
    "\n",
    "        dates = soup.find_all(\"time\")\n",
    "\n",
    "        data = []\n",
    "\n",
    "        for message, date in zip(messages, dates):\n",
    "            message_text = message.get_text(strip = True)\n",
    "            date_text = date.get(\"title\")\n",
    "            data.append({\"Date\": date_text, \"Message\": message_text})\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "def scrape_forum(base_url, total_pages):\n",
    "    all_data = []\n",
    "\n",
    "    for page_num in range(1, total_pages + 1):\n",
    "        page_url = f\"{base_url}/p{page_num}\"\n",
    "        print(f\"Scraping page {page_num}: {page_url}\")\n",
    "        page_data = scrape_page(page_url)\n",
    "        all_data.extend(page_data)\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://forums.edmunds.com/discussion/2864/general/x/entry-level-luxury-performance-sedans\"\n",
    "total_pages = 300\n",
    "forum_data = scrape_forum(base_url, total_pages)\n",
    "messagedata = pd.DataFrame(forum_data)\n",
    "messagedata.to_csv(\"messagedata.csv\", index = False)\n",
    "len(messagedata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B\n",
    "\n",
    "Assume that a customer, who will be using this recommender system, has specified 3 attributes in a product. E.g., one website describes multiple attributes of beer (but you should choose attributes from the actual data like you did for the first assignment)\n",
    "\n",
    "https://www.dummies.com/food-drink/drinks/beer/beer-for-dummies-cheat-sheet/\n",
    "- Aggressive (Boldly assertive aroma and/or taste) \n",
    "- Balanced: Malt and hops in similar proportions; equal representation of malt sweetness and hop bitterness in the flavor — especially at the finish\n",
    "- Complex: Multidimensional; many flavors and sensations on the palate\n",
    "- Crisp: Highly carbonated; effervescent\n",
    "- Fruity: Flavors reminiscent of various fruits or Hoppy: Herbal, earthy, spicy, or citric aromas and flavors of hops or Malty: Grainy, caramel-like; can be sweet or dry\n",
    "- Robust: Rich and full-bodied\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task C\n",
    "\n",
    "Perform a similarity analysis using cosine similarity (without word embeddings – i.e., using the bag-of-words model) with the 3 attributes specified by the customer and the reviews. \n",
    "The similarity script should accept as input a file with the product attributes, and calculate similarity scores (between 0 and 1) between these attributes and each review. That is, the output file should have 3 columns – product_name (for each product, the product_name will repeat as many times as there are reviews of the product), product_review and similarity_score. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task D\n",
    "\n",
    "For every review, perform a sentiment analysis (using VADER or any LLM). In case you have to change the default values of words in the VADER lexicon, use this article: https://medium.com/swlh/adding-context-to-unsupervised-sentiment-analysis-7b6693d2c9f8 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task E\n",
    "\n",
    "Create an evaluation score for each beer that uses both similarity and sentiment scores. \n",
    "Now recommend 3 products to the customer. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task F \n",
    "\n",
    "How would your recommendations change if you use word vectors (e.g., the spaCy package with medium sized pretrained word vectors) instead of the plain vanilla bag-of-words cosine similarity? One way to analyze the difference would be to consider the % of reviews that mention a preferred attribute. E.g., if you recommend a product, what % of its reviews mention an attribute specified by the customer? Do you see any difference across bag-of-words and word vector approaches? Explain. This article may be useful: https://medium.com/swlh/word-embeddings-versus-bag-of-words-the-curious-case-of-recommender-systems-6ac1604d4424?source=friends_link&sk=d746da9f094d1222a35519387afc6338\n",
    "\n",
    "\n",
    "Note that the article doesn’t claim that bag-of-words will always be better than word embeddings for recommender systems. It lays out conditions under which it is likely to be the case. That is, depending on the attributes you use, you may or may not see the same effect. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task G\n",
    "\n",
    "How would your recommendations differ if you ignored the similarity and feature sentiment scores and simply chose the 3 highest rated products from your entire dataset? Would these products meet the requirements of the user looking for recommendations? Why or why not? Justify your answer with analysis. Use the similarity and sentiment scores as well as overall ratings to answer this question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task H\n",
    "\n",
    "Choose any 10 beers in your data. Now choose any one of them, and find the most similar beer (among the remaining 9). Explain your method and logic. https://medium.datadriveninvestor.com/who-is-your-competitor-in-the-era-of-the-long-tail-d0ac24fedde8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

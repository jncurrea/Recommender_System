{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in scraped data file\n",
    "data = pd.read_csv('translated_messages.csv')\n",
    "text = data['translated_messages'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out how to take in user attributes\n",
    "# Take in 3 user attributes\n",
    "attribute1 = input(\"Enter the first attribute: \")\n",
    "attribute2 = input(\"Enter the second attribute: \")\n",
    "attribute3 = input(\"Enter the third attribute: \")\n",
    "\n",
    "# Combine the attributes into a single string\n",
    "attributes_combined = \" \".join([attribute1, attribute2, attribute3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thick\n",
      "rich\n",
      "bodied\n"
     ]
    }
   ],
   "source": [
    "print(attribute1)\n",
    "print(attribute2)\n",
    "print(attribute3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Each Message to Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8231\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "#  Fit to text \n",
    "count_matrix = count_vectorizer.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      00  000  000th  001  00am  00th  01  010515  011  02  ...  ølbutik  \\\n",
      "0      0    0      0    0     0     0   0       0    0   0  ...        0   \n",
      "1      0    0      0    0     0     0   0       0    0   0  ...        0   \n",
      "2      0    0      0    0     0     0   0       0    0   0  ...        0   \n",
      "3      0    0      0    0     0     0   0       0    0   0  ...        0   \n",
      "4      0    0      0    0     0     0   0       0    0   0  ...        0   \n",
      "...   ..  ...    ...  ...   ...   ...  ..     ...  ...  ..  ...      ...   \n",
      "8226   0    0      0    0     0     0   0       0    0   0  ...        0   \n",
      "8227   0    0      0    0     0     0   0       0    0   0  ...        0   \n",
      "8228   0    0      0    0     0     0   0       0    0   0  ...        0   \n",
      "8229   0    0      0    0     0     0   0       0    0   0  ...        0   \n",
      "8230   0    0      0    0     0     0   0       0    0   0  ...        0   \n",
      "\n",
      "      øldage  ølfestival  ølklubben  øllets  østerfælled  über  überragend  \\\n",
      "0          0           0          0       0            0     0           0   \n",
      "1          0           0          0       0            0     0           0   \n",
      "2          0           0          0       0            0     0           0   \n",
      "3          0           0          0       0            0     0           0   \n",
      "4          0           0          0       0            0     0           0   \n",
      "...      ...         ...        ...     ...          ...   ...         ...   \n",
      "8226       0           0          0       0            0     0           0   \n",
      "8227       0           0          0       0            0     0           0   \n",
      "8228       0           0          0       0            0     0           0   \n",
      "8229       0           0          0       0            0     0           0   \n",
      "8230       0           0          0       0            0     0           0   \n",
      "\n",
      "      świat  żytnia  \n",
      "0         0       0  \n",
      "1         0       0  \n",
      "2         0       0  \n",
      "3         0       0  \n",
      "4         0       0  \n",
      "...     ...     ...  \n",
      "8226      0       0  \n",
      "8227      0       0  \n",
      "8228      0       0  \n",
      "8229      0       0  \n",
      "8230      0       0  \n",
      "\n",
      "[8231 rows x 15818 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "count_array = count_matrix.toarray()\n",
    "df = pd.DataFrame(data=count_array, columns=count_vectorizer.get_feature_names_out())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Review Vectors and Attribute Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the review vectors, calculate the magnitude of each review vector (L2 norm)\n",
    "magnitude = np.linalg.norm(df, axis=1)\n",
    "\n",
    "# Avoid division by zero\n",
    "magnitude[magnitude == 0] = 1\n",
    "\n",
    "# Normalize each review vector (divide by its magnitude)\n",
    "normalized_reviews = df.div(magnitude, axis=0)\n",
    "\n",
    "# Transform attribute string into a vector\n",
    "attribute_vector = count_vectorizer.transform([attributes_combined]).toarray()\n",
    "\n",
    "# Calculate magnitude of the attribute vector, avoid division by zero\n",
    "attribute_magnitude = np.linalg.norm(attribute_vector)\n",
    "if attribute_magnitude == 0:\n",
    "    attribute_magnitude = 1\n",
    "\n",
    "# Normalize the attribute vector by dividing each element by its magnitude\n",
    "normalized_attribute_vector = attribute_vector / attribute_magnitude\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Cosine Similarity Between Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_scores = cosine_similarity(normalized_reviews, normalized_attribute_vector).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Create the output DataFrame\n",
    "# Include product_name, product_review, and similarity_score\n",
    "output_df = pd.DataFrame({\n",
    "    \"product_name\": data['Beer Name'],           # From the original CSV file\n",
    "    \"product_review\": data['translated_messages'], # Review text\n",
    "    \"similarity_score\": similarity_scores         # Calculated similarity score\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv(\"review_similarity_scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis Using VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/jennamferguson/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the VADER lexicon\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Create sentiment analyzer object\n",
    "sid = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all values in 'product_review' are strings and handle NaNs\n",
    "output_df['product_review'] = output_df['product_review'].fillna(\"\").astype(str)\n",
    "\n",
    "# Add a new column to the output_df with sentiment scores\n",
    "output_df['sentiment_score'] = output_df['product_review'].apply(lambda review: sid.polarity_scores(review)['compound'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Save the updated DataFrame to a new CSV file\n",
    "output_df.to_csv(\"review_similarity_scores_sentiment.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

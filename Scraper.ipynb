{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rate My Beer Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up ChromeDriver path\n",
    "driver_path = \"/Users/ramzikattan/Downloads/chromedriver-mac-arm64/chromedriver\"\n",
    "chrome_path = \"/Applications/Google Chrome.app/Contents/MacOS/Google Chrome\"\n",
    "\n",
    "# Configure Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.binary_location = chrome_path\n",
    "\n",
    "# Set up the Chrome WebDriver service\n",
    "service = Service(driver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Open the webpage\n",
    "url = \"https://www.ratebeer.com/top-beers?time=all\"\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Parse the page with BeautifulSoup\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Close the browser after fetching the page\n",
    "driver.quit()\n",
    "\n",
    "# Find all <a> tags with the class containing the beer name and link\n",
    "beer_links = soup.find_all('a', class_=\"MuiTypography-root\")\n",
    "\n",
    "# Extract the name and URL for each beer\n",
    "beers = []\n",
    "for beer in beer_links:\n",
    "    name = beer.get_text(strip=True)  # Get the text (beer name)\n",
    "    link = beer['href']  # Get the URL\n",
    "    full_link = \"https://www.ratebeer.com\" + link  # Construct full URL\n",
    "    beers.append({'name': name, 'link': full_link})\n",
    "\n",
    "# Print the extracted beer names and their URLs\n",
    "#for beer in beers:\n",
    " #   print(f\"Beer: {beer['name']} - URL: {beer['link']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the matrix for only the beer links\n",
    "cleaned_beers = [beer for beer in beers[28:128] if beer['name']]  # Only keep non-empty names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping reviews for Toppling Goliath Kentucky BrunchðŸ‡ºðŸ‡¸Stout - Imperial Flavored / Pastry at https://www.ratebeer.com/beer/toppling-goliath-kentucky-brunch/166019/...\n",
      "Finished scraping Toppling Goliath Kentucky BrunchðŸ‡ºðŸ‡¸Stout - Imperial Flavored / Pastry.\n",
      "Scraping reviews for NÃ¤rke Kaggen StormaktsporterðŸ‡¸ðŸ‡ªStout - Imperial at https://www.ratebeer.com/beer/naerke-kaggen-stormaktsporter/58057/...\n",
      "No cookies banner found or failed to dismiss.\n",
      "Finished scraping NÃ¤rke Kaggen StormaktsporterðŸ‡¸ðŸ‡ªStout - Imperial.\n",
      "Scraping reviews for Schramm's The Heart of DarknessðŸ‡ºðŸ‡¸Mead - Melomel / Fruited at https://www.ratebeer.com/beer/schramm-s-the-heart-of-darkness/231441/...\n",
      "No cookies banner found or failed to dismiss.\n",
      "Finished scraping Schramm's The Heart of DarknessðŸ‡ºðŸ‡¸Mead - Melomel / Fruited.\n",
      "Scraping reviews for Westvleteren 12ðŸ‡§ðŸ‡ªQuadrupel / Abt at https://www.ratebeer.com/beer/westvleteren-12/4934/...\n",
      "No cookies banner found or failed to dismiss.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# Configure Chrome options for headless mode\n",
    "chrome_options = Options()\n",
    "chrome_options.binary_location = chrome_path  # Path to your Chrome browser\n",
    "chrome_options.add_argument('--headless')  # Enable headless mode to run faster\n",
    "chrome_options.add_argument('--disable-gpu')  # Disable GPU acceleration (for better performance in headless mode)\n",
    "chrome_options.add_argument('--no-sandbox')  # Added for safe execution in certain environments\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')  # Avoid issues with shared memory\n",
    "\n",
    "# Set up the Chrome WebDriver service\n",
    "service = Service(driver_path)  # Path to your ChromeDriver\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Function to click \"Show More\" buttons on the current page\n",
    "def click_show_more_buttons():\n",
    "    # Locate all \"Show More\" buttons on the page\n",
    "    show_more_xpath = '//span[contains(@class, \"MuiButton-label\") and text()=\"Show more\"]'\n",
    "    show_more_buttons = driver.find_elements(By.XPATH, show_more_xpath)\n",
    "\n",
    "    # Click each \"Show More\" button\n",
    "    for button in show_more_buttons:\n",
    "        try:\n",
    "            if button.is_displayed():\n",
    "                driver.execute_script(\"arguments[0].click();\", button)\n",
    "                time.sleep(1)  # Wait for the content to expand\n",
    "        except:\n",
    "            pass  # Skip if there's an issue clicking the button\n",
    "\n",
    "# Function to scrape reviews on the current page\n",
    "def scrape_reviews():\n",
    "    reviews = []\n",
    "    ratings_xpath = '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"bRPQdN\", \" \" )) and contains(concat( \" \", @class, \" \" ), concat( \" \", \"MuiTypography-subtitle1\", \" \" ))]'  # Adjust this based on your page's structure for ratings\n",
    "    messages_xpath = '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"pre-wrap\", \" \" )) and contains(concat( \" \", @class, \" \" ), concat( \" \", \"MuiTypography-body1\", \" \" ))]'  # Adjust this based on your page's structure for review messages\n",
    "\n",
    "    # Find all the review ratings and messages on the current page\n",
    "    ratings = driver.find_elements(By.XPATH, ratings_xpath)\n",
    "    messages = driver.find_elements(By.XPATH, messages_xpath)\n",
    "\n",
    "    for i, message in enumerate(messages):\n",
    "        reviews.append({\n",
    "            'rating': ratings[i].text if i < len(ratings) else None,  # Handle index if ratings and messages mismatch\n",
    "            'message': message.text\n",
    "        })\n",
    "\n",
    "    return reviews\n",
    "\n",
    "# Function to scrape reviews for a single beer URL\n",
    "def scrape_beer_reviews(beer_name, url):\n",
    "    all_reviews = []\n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(2)  # Let the page load fully\n",
    "\n",
    "    # Handle the cookies banner by accepting it\n",
    "    try:\n",
    "        accept_cookies_id = 'onetrust-accept-btn-handler'\n",
    "        accept_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, accept_cookies_id)))\n",
    "        accept_button.click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        print(\"No cookies banner found or failed to dismiss.\")\n",
    "        pass\n",
    "\n",
    "    while True:\n",
    "        # Click all \"Show More\" buttons to expand reviews\n",
    "        click_show_more_buttons()\n",
    "\n",
    "        # Scrape reviews on the current page\n",
    "        page_reviews = scrape_reviews()\n",
    "        all_reviews.extend(page_reviews)\n",
    "\n",
    "        # Find the \"Next\" button and move to the next page\n",
    "        try:\n",
    "            next_button_xpath = '//button[@aria-label=\"Next page\" and contains(@class, \"MuiIconButton-root\")]'\n",
    "            next_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, next_button_xpath)))\n",
    "            next_button.click()\n",
    "\n",
    "            # Wait for the next page to load\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            # If there's no \"Next\" button, break the loop\n",
    "            print(f\"Finished scraping {beer_name}.\")\n",
    "            break\n",
    "\n",
    "    return all_reviews\n",
    "\n",
    "# Initialize an empty DataFrame to store all the reviews\n",
    "df = pd.DataFrame(columns=['Beer Name', 'URL', 'Rating', 'Review'])\n",
    "\n",
    "# Iterate through each beer in the cleaned_beers list\n",
    "for beer in cleaned_beers:\n",
    "    beer_name = beer['name']\n",
    "    beer_url = beer['link']\n",
    "\n",
    "    print(f\"Scraping reviews for {beer_name} at {beer_url}...\")\n",
    "\n",
    "    # Scrape reviews for the current beer\n",
    "    reviews = scrape_beer_reviews(beer_name, beer_url)\n",
    "\n",
    "    # Create a DataFrame for the reviews of the current beer\n",
    "    beer_df = pd.DataFrame(reviews)\n",
    "    beer_df['Beer Name'] = beer_name\n",
    "    beer_df['URL'] = beer_url\n",
    "\n",
    "    # Append the DataFrame for this beer to the overall DataFrame\n",
    "    df = pd.concat([df, beer_df], ignore_index=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('beer_reviews.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Close the browser after scraping all URLs\n",
    "driver.quit()\n",
    "\n",
    "print(\"Scraping completed. Data saved to 'beer_reviews.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping reviews for Toppling Goliath Kentucky BrunchðŸ‡ºðŸ‡¸Stout - Imperial Flavored / Pastry at https://www.ratebeer.com/beer/toppling-goliath-kentucky-brunch/166019/...\n",
      "Scraping reviews for NÃ¤rke Kaggen StormaktsporterðŸ‡¸ðŸ‡ªStout - Imperial at https://www.ratebeer.com/beer/naerke-kaggen-stormaktsporter/58057/...\n",
      "No cookies banner found or failed to dismiss.\n",
      "Scraping reviews for Schramm's The Heart of DarknessðŸ‡ºðŸ‡¸Mead - Melomel / Fruited at https://www.ratebeer.com/beer/schramm-s-the-heart-of-darkness/231441/...\n",
      "No cookies banner found or failed to dismiss.\n",
      "Scraping completed. Data saved to 'beer_reviews.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# Configure Chrome options for headless mode\n",
    "chrome_options = Options()\n",
    "chrome_options.binary_location = chrome_path  # Path to your Chrome browser\n",
    "chrome_options.add_argument('--headless')  # Enable headless mode to run faster\n",
    "chrome_options.add_argument('--disable-gpu')  # Disable GPU acceleration (for better performance in headless mode)\n",
    "chrome_options.add_argument('--no-sandbox')  # Added for safe execution in certain environments\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')  # Avoid issues with shared memory\n",
    "\n",
    "# Set up the Chrome WebDriver service\n",
    "service = Service(driver_path)  # Path to your ChromeDriver\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Function to click \"Show More\" buttons on the current page\n",
    "def click_show_more_buttons():\n",
    "    # Locate all \"Show More\" buttons on the page\n",
    "    show_more_xpath = '//span[contains(@class, \"MuiButton-label\") and text()=\"Show more\"]'\n",
    "    show_more_buttons = driver.find_elements(By.XPATH, show_more_xpath)\n",
    "\n",
    "    # Click each \"Show More\" button\n",
    "    for button in show_more_buttons:\n",
    "        try:\n",
    "            if button.is_displayed():\n",
    "                driver.execute_script(\"arguments[0].click();\", button)\n",
    "                time.sleep(1)  # Wait for the content to expand\n",
    "        except:\n",
    "            pass  # Skip if there's an issue clicking the button\n",
    "\n",
    "# Function to scrape reviews on the current page\n",
    "def scrape_reviews():\n",
    "    reviews = []\n",
    "    ratings_xpath = '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"bRPQdN\", \" \" )) and contains(concat( \" \", @class, \" \" ), concat( \" \", \"MuiTypography-subtitle1\", \" \" ))]'  # Adjust this based on your page's structure for ratings\n",
    "    messages_xpath = '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"pre-wrap\", \" \" )) and contains(concat( \" \", @class, \" \" ), concat( \" \", \"MuiTypography-body1\", \" \" ))]'  # Adjust this based on your page's structure for review messages\n",
    "\n",
    "    # Find all the review ratings and messages on the current page\n",
    "    ratings = driver.find_elements(By.XPATH, ratings_xpath)\n",
    "    messages = driver.find_elements(By.XPATH, messages_xpath)\n",
    "\n",
    "    for i, message in enumerate(messages):\n",
    "        reviews.append({\n",
    "            'rating': ratings[i].text if i < len(ratings) else None,  # Handle index if ratings and messages mismatch\n",
    "            'message': message.text\n",
    "        })\n",
    "\n",
    "    return reviews\n",
    "\n",
    "# Function to scrape reviews for a single beer URL with a limit of 250 reviews\n",
    "def scrape_beer_reviews(beer_name, url, review_limit=250):\n",
    "    all_reviews = []\n",
    "    \n",
    "    driver.get(url)\n",
    "    time.sleep(2)  # Let the page load fully\n",
    "\n",
    "    # Handle the cookies banner by accepting it\n",
    "    try:\n",
    "        accept_cookies_id = 'onetrust-accept-btn-handler'\n",
    "        accept_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, accept_cookies_id)))\n",
    "        accept_button.click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        print(\"No cookies banner found or failed to dismiss.\")\n",
    "        pass\n",
    "\n",
    "    # Loop through pages and scrape reviews until the limit is reached\n",
    "    while len(all_reviews) < review_limit:\n",
    "        # Click all \"Show More\" buttons to expand reviews\n",
    "        click_show_more_buttons()\n",
    "\n",
    "        # Scrape reviews on the current page\n",
    "        page_reviews = scrape_reviews()\n",
    "        all_reviews.extend(page_reviews)\n",
    "\n",
    "        # Check if we've hit the review limit\n",
    "        if len(all_reviews) >= review_limit:\n",
    "            all_reviews = all_reviews[:review_limit]  # Truncate to exactly the review limit\n",
    "            break\n",
    "\n",
    "        # Find the \"Next\" button and move to the next page\n",
    "        try:\n",
    "            next_button_xpath = '//button[@aria-label=\"Next page\" and contains(@class, \"MuiIconButton-root\")]'\n",
    "            next_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, next_button_xpath)))\n",
    "            next_button.click()\n",
    "\n",
    "            # Wait for the next page to load\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            # If there's no \"Next\" button, break the loop\n",
    "            print(f\"Finished scraping {beer_name}.\")\n",
    "            break\n",
    "\n",
    "    return all_reviews\n",
    "\n",
    "# Initialize an empty DataFrame to store all the reviews\n",
    "df = pd.DataFrame(columns=['Beer Name', 'URL', 'Rating', 'Review'])\n",
    "\n",
    "# Iterate through each beer in the cleaned_beers list\n",
    "for beer in cleaned_beers[0:3]:\n",
    "    beer_name = beer['name']\n",
    "    beer_url = beer['link']\n",
    "\n",
    "    print(f\"Scraping reviews for {beer_name} at {beer_url}...\")\n",
    "\n",
    "    # Scrape reviews for the current beer with a limit of 250 reviews\n",
    "    reviews = scrape_beer_reviews(beer_name, beer_url, review_limit=5)\n",
    "\n",
    "    # Create a DataFrame for the reviews of the current beer\n",
    "    beer_df = pd.DataFrame(reviews)\n",
    "    beer_df['Beer Name'] = beer_name\n",
    "    beer_df['URL'] = beer_url\n",
    "\n",
    "    # Append the DataFrame for this beer to the overall DataFrame\n",
    "    df = pd.concat([df, beer_df], ignore_index=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('beer_reviews.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Close the browser after scraping all URLs\n",
    "driver.quit()\n",
    "\n",
    "print(\"Scraping completed. Data saved to 'beer_reviews.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
